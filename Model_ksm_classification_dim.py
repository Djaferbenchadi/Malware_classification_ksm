# %%

import subprocess
import hdf5storage
import numpy as np
from sklearn.preprocessing import normalize

def run_script(sgm, subdim_info):
  cmd = ['python', 'script.py', '--sgm', str(sgm), '--subdim_info', str(subdim_info[0]), str(subdim_info[1])]
  subprocess.run(cmd)


## Settings for Subspace dimension: for each malware family we select the subspace dimension according to the variance 
parameter_sets = [
  (0.1, np.array([1,3,1,1,1,1,1,3,1,2,2,1,4,4,2,3,1,1,1,1,3,5,17,1,1])),
  (0.1, np.array([1,4,1,1,2,1,3,5,1,2,3,1,5,5,2,5,1,1,1,2,5,7,19,1,1])),
  (0.1, np.array([1,4,1,1,2,1,3,6,1,2,3,1,6,5,2,5,1,1,1,2,5,8,20,1,1])),
  (0.1, np.array([1,6,1,1,2,1,3,6,1,3,3,1,6,6,2,6,1,1,1,2,6,9,20,1,1])),
  (0.1, np.array([1,8,1,1,2,1,4,7,1,3,3,1,7,6,2,8,1,1,1,2,6,9,21,1,1])),
  (0.1, np.array([1,12,1,1,2,1,4,7,2,3,3,1,8,7,2,10,1,1,1,2,7,10,21,1,1])),
  (0.1, np.array([1,15,1,1,3,1,5,8,2,3,3,1,9,7,2,12,1,1,1,2,8,10,22,1,1])),
  (0.1, np.array([1,41,2,1,4,1,11,15,3,3,5,1,14,12,3,42,2,1,4,3,13,16,26,1,1])),
  (0.1, np.array([1,48,4,14,5,1,13,17,3,3,5,1,16,13,3,52,3,1,5,3,15,18,27,1,1])),
  (0.1, np.array([1,56,32,91,6,1,15,20,4,3,7,1,19,15,3,63,4,1,9,3,18,21,28,2,1])),
  (0.1, np.array([2,65,162,206,23,1,19,24,10,3,9,1,22,18,4,76,15,1,14,4,24,26,32,2,1])),
  (0.1, np.array([2,76,386,386,73,1,27,36,35,3,14,2,28,21,5,93,45,1,27,4,36,41,51,3,1])),
  (0.1, np.array([2,83,575,541,110,1,53,62,62,3,18,2,35,25,5,104,68,1,40,5,60,65,91,7,1])),
  (0.1, np.array([4,88,763,701,142,1,106,89,92,4,22,3,41,28,8,112,88,1,53,7,82,87,160,14,1]))
]



train_x = []
test_x_ = []

for i in range(1, 26):
    file_name = "X" + str(i) + ".mat"
    file_path = "MALIMG_multiple/" + file_name
    data = hdf5storage.loadmat(file_path)
    variable_name = "X"+str(i)
    data_transposed = np.array(data[variable_name].T)
    train_x.append(data_transposed)

for i in range(1, 26):
    file_name = "Y" + str(i) + ".mat"
    file_path = "MALIMG_multiple/" + file_name
    data = hdf5storage.loadmat(file_path)
    variable_name = "Y"+str(i)
    data_transposed = np.array(data[variable_name].T)
    test_x_.append(data_transposed)
    
train_y = np.arange(25)



test_x_all = np.concatenate(test_x_, axis=0)
test_x = [test_x_all[i, np.newaxis, :] for i in range(test_x_all.shape[0])]
test_y = np.concatenate([np.full(len(test_x_[i]), i) for i in range(len(test_x_))])


#parameter-------------------------------------------------------------------------------
class_num = 25                          
class_info = np.array([97, 91, 2824, 1491, 173, 81, 175, 121, 152, 137, 306, 356, 153, 159, 98, 134, 111, 117, 133, 55, 103, 107, 383, 72, 775])   
#----------------------------------------------------------------------------------------


#normalization---------------------------------------------------------------------------
class_index = []
count_c = 0
for class_i in class_info:
    if count_c == 0:
        class_index.append(0)
        class_index.append(class_info[0])
    else:
        class_index.append(class_index[count_c] + class_info[count_c])
    count_c += 1
class_index = np.array(class_index)

count = 0
for train_data in train_x:
    train_x[count] = normalize(train_data, axis=1)
    count += 1
count = 0
for test_data in test_x:
    test_x[count] = normalize(test_data, axis=1)
    count += 1
#----------------------------------------------------------------------------------------


#------------------------for training------------------------

for sgm, subdim_info in parameter_sets:
  run_script(sgm, subdim_info)
  for var in list(globals().keys()):
    if var not in ['function variables','accuracy_score','gauss_class_mat_diff','gauss_gram_mat','gauss_gram_two','gauss_projection_diff','get_ipython','jit','parentpath1','rand','randint','run_script','trace_this_thread','train_test_split','special variables','__','___','__doc__','__file__','__loader__','__name__','__package__','__spec__','__vsc_ipynb_file__','__builtin__','__builtins__','debugpy','exit','hdf5storage','np','os','pd','quit','random','subprocess','sys','_VSCODE_hashlib','_VSCODE_types','_dh','_VSCODE_compute_hash','_VSCODE_wrapped_run_cell','normalize','sgm', 'subdim_info', 'train_x','train_y','test_x','test_y','Accuracy', 'dimension_safe', 'dimension_mal']:
      del globals()[var]

  import os
  from numpy.random import randint, rand
  from sklearn.model_selection import train_test_split
  from sklearn.metrics import accuracy_score
  import random
  import matplotlib.pyplot as plt
  from numba import jit, void, f8, njit  
  from sklearn.metrics import confusion_matrix
  from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support
  import pandas as pd
  from numpy.random import randint, rand
  from numba import jit, void, f8, njit
  import seaborn as sns

  @jit(void(f8[:, :], f8[:, :]))
  def gauss_gram_mat(x, K):
    n_points = len(x)
    n_dim = len(x[0])
    b = 0
    for j in range(n_points):
      for i in range(n_points):
        for k in range(n_dim):
          b = (x[i][k] - x[j][k])
          K[i][j] += b * b
  @jit
  def gauss_gram_two(X, Y, K_t):
      for i in range(X.shape[0]):
          for j in range(Y.shape[0]):
              for k in range(X.shape[1]):
                  b = (X[i][k] - Y[j][k])
                  K_t[i][j] += b * b

  def parentpath1(path=__file__, f=0):
      return str(os.path.abspath(""))

  def l2_kernel(X, Y): ##L2-norms of x and y.
      XX = (X ** 2).sum(axis=0)[:, None]
      YY = (Y ** 2).sum(axis=0)[None, :]

      return XX - 2 * (X.T @ Y) + YY
   
  def dual_vectors(K, n_subdims=None, higher=True, elim=False, eps=1e-6):
      e, A = np.linalg.eigh(K)
      e[(e < eps)] = eps

      A = A / np.sqrt(e)

      if elim:
          e = e[(e > eps)]
          A = A[:, (e > eps)]

      if higher:
          return A[:, -n_subdims:]

      return A[:, :n_subdims]


  print("sigma:",sgm,"subdim_info:",subdim_info)   
 
  K_class = []
  count_class = 0

  for train_data in train_x:

      K1 = np.zeros((train_data.shape[0], train_data.shape[0]))
      gauss_gram_mat(train_data, K1)
      K1 = np.exp(- K1 / (2 * sgm))
      X1_coeffs = dual_vectors(K1, n_subdims=subdim_info[count_class])
      K_class.append(X1_coeffs)
      count_class += 1



  #------------------------for testing------------------------
  # Kernel projection for testing data 
  test_np = np.array(test_x)
  test_np = test_np.reshape([test_np.shape[0], test_np.shape[2]])

  K_input = []
  for train_data in train_x:
      K_1 = np.zeros((test_np.shape[0], train_data.shape[0]))
      gauss_gram_two(test_np, train_data, K_1)
      K_1 = np.exp(- K_1 / (2 * sgm))
      K_1 = K_1.T
      K_input.append(K_1)

  #--------------------Calculate projection length--------------------

  similarity_all = []
  similarity_all_1 = []

  for j in range(25):
      similarity = []
      for i in range(K_input[j].shape[1]):
          data_input = K_input[j][:, i]
          length = np.linalg.norm(K_class[j].T @ data_input, ord=2)
          similarity.append(length)
      similarity_all.append(similarity)

  for k in range(935):
      max_similarity = -1
      max_label = -1
      for i in range(25):
          if similarity_all[i][k] > max_similarity:
              max_similarity = similarity_all[i][k]
              max_label = i
      similarity_all_1.append(max_label)


  Accuracy = accuracy_score(similarity_all_1, test_y)
  print("accuracy:", Accuracy)


  conf_mat = confusion_matrix(test_y, similarity_all_1)
  plt.figure(figsize=(10,8))
  sns.heatmap(conf_mat,annot=True,fmt='d',cmap='Blues',xticklabels=['Adialer.C', 'Agent.FYI', 'Allaple.A', 'Allaple.L', 'Alueron.gen!J', 'Autorun.K', 'C2LOP.gen!g', 'C2LOP.P', 'Dialplatform.B','Dontovo.A','Fakerean','Instantaccess' ,'Lolyda.AA1','Lolyda.AA2','Lolyda.AA3','Lolyda.AT','Malex.gen!J','Obfuscator.AD','Rbot!gen','Skintrim.N','Swizzor.gen!E','Swizzor.gen!I','VB.AT','Wintrim.BX','Yuner.A'],yticklabels=['Adialer.C', 'Agent.FYI', 'Allaple.A', 'Allaple.L', 'Alueron.gen!J', 'Autorun.K', 'C2LOP.gen!g', 'C2LOP.P', 'Dialplatform.B','Dontovo.A','Fakerean','Instantaccess' ,'Lolyda.AA1','Lolyda.AA2','Lolyda.AA3','Lolyda.AT','Malex.gen!J','Obfuscator.AD','Rbot!gen','Skintrim.N','Swizzor.gen!E','Swizzor.gen!I','VB.AT','Wintrim.BX','Yuner.A'])
  plt.xlabel('Predicted labels')
  plt.ylabel('True labels')
  plt.show()
